- to choose what set of functions to use is hard
  - might need domain knowledge
  - need exploration
  - so, DL didn't simplify problems. It just transformed the problem to another problem.
- if a problem is too easy or abstract for humans, then the improvement with DL is larger, as it's harder for humans to manually do feature engineering.
##### Back propagation
- goal: to compute the gradients efficiently.
- how: like build a backwards NN (compute dL/dz backwards)

#### General Instructions of Modeling
- make model more complex (针就不在大海里)
  - more features
  - use DL
- make model less complex
  - more training data
  - data augmentation
  - make model simpler
    - less params / sharing params
    - less features
    - early stop
    - regularization
    - dropout
- optimization (针在大海里, 但没找到)
  - potential large loss reason. easy to ignore.
  - how to find: insights from comparison
    - start from shallower NN's (or not dl models)
    - If deeper model doesn't get smaller loss on training data, then it's a optimization problem
  - solution (TBC)
- mismatch
  - training and testing data have different distributions (solution: TBC: HW11)

##### Cross Validation (training, validation (from training data), testing)
  - )( don't use public leaderboard results to choose the model (Kaggle), as a random sampled one might luckily have a good result on the public leaderboard data set. (won't be lucky on the private one...)
  - right way: just rely on the validation set performance (the selected small data set in the training data)

#### Optimization (GD)
##### Optimization fails because...
- stuck at critical point:
  - 1> local minima
  - 2> saddle point (Gradient==0, but is not local nor global minima)
  - To distinguish b/w:
    - Tayler Series Approximation (When gradient item ==0, use Hessian item)
    - If Hessian matrix s.t.:
      - 1> any v: v'Hv > 0 [is positive definite matrix] => local minima
      - 2> any v: v'Hv < 0 => local maxima
      - 3> some > 0 some < 0 => saddle point
