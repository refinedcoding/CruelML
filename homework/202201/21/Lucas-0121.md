- https://www.coursera.org/learn/machine-learning/lecture/3iawu/gradient-descent-in-practice-ii-learning-rate
- 如何选择学习速率 alpha，目标是找到损耗函数的最小值
- 随着不断迭代，目标函数不断变小
- 学习速率太大，损耗函数容易震荡，所以要用小一点的学习速率
- 学习速率小，收敛较慢 convergence
- 学习速率大，，损耗函数在每次迭代的时候不一定降低，也有可能不收敛

- TODO: 6:58/8:58
