#### 6.1 Example: Learning XOR
- Used XOR function as an example of nn
- treat this problem as a regression problem and use a mean squared error loss function (to simplify the math)
- Tried to all use linear function:
  - Unfortunately, if both f(1) and f(2) were linear, then the feedforward network as a whole would remain a linear function of its input
  - But the data we saw is clearly not linear, so we need to introduce nonlinear functions =>
- **activation function**: a fixed, **nonlinear** function
  - in the e.g., the nonlinear features have mapped two points into a single point in feature space. The motivation for learning the feature space is only to make the model capacity greater so that it can fit the training set. In more realistic applications, learned representations can also help the model to generalize.
- In this e.g., The neural network has obtained the correct answer for every example in the batch. 
- But genearlly, a **gradient-based optimization algorithm** can find parameters that produce very little error.
