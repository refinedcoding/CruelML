- 梯度下降算法可以保证找到任意函数J(theta0, theta1)损耗函数的最小值，错？
- 如果alpha保持不变，梯度下降可以收敛。但是alpha不能太大，如果太大，就不能收敛。对？
- 对于在线性回归中损耗函数J(theta0, theta1)的特定选择，没有局部的优化，相对的，只有全局优化。
- TODO: https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression, 9:08/10:20


