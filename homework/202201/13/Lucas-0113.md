- Course:
https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression
- 二元求导，theta(0), sum((h(x) - y)/m, theta(1), sum(h(x) - y)*x / m
- Gradient Descent Algorithm, 梯度下降算法，同时更新theta(0) 和 theta(1)
- Convex Function, 凸函数, 碗状图形, TODO: Python算法实现
- 批量梯度下降算法，每一步使用所有的训练数据
- 为了使梯度下降收敛converge，我们必须每次缓慢地减少alpha，错？
