# ESL: pp 101-110

## Linear Methods for Classification

#### Introduction

åˆ¤åˆ«è¾¹ç•Œ decision boundaries

- ç¬¬ $k$ ç±»å’Œç¬¬ $l$ ç±»çš„åˆ¤åˆ«è¾¹ç•Œæ˜¯æ»¡è¶³ $\hat f_k(x)=\hat f_\ell (x)$ çš„ç‚¹çš„é›†åˆ $\{x:(\hat\beta_{k0}-\hat\beta_{\ell0})+(\hat\beta_k-\hat\beta_\ell)^Tx=0\}$ è¶…å¹³é¢ã€‚

- è¾“å…¥ç©ºé—´è¢«åˆ†å—è¶…å¹³é¢åˆ¤åˆ«è¾¹ç•Œåˆ†æˆäº†è‹¥å¹²ä¸ªç±»åˆ«åŒºåŸŸ

- å›å½’æ–¹æ³•å¯¹æ¯ä¸ªç±»åˆ«å»ºç«‹ åˆ¤åˆ«å‡½æ•° (discriminant function) $\delta_k(x)$ï¼Œå°† $x$ åˆ†åˆ°å–æœ€å¤§çš„åˆ¤åˆ«å‡½æ•°æ‰€åœ¨ç±»åˆ«ä¸­ã€‚

åªè¦$\delta_k(x)$ æ˜¯å…³äº$x$ çº¿æ€§çš„ï¼Œåˆ™åˆ¤åˆ«è¾¹ç•Œä¹Ÿå°†æ˜¯çº¿æ€§çš„ã€‚



#### Linear Regression of an Indicator Matrix

$K$ ä¸ªç±»åˆ«ï¼Œ$Y_k\in\{0,1\}$.

$N$ ä¸ª training sample

$Y\in\{0,1\}^{N\times K}$: indicator response matrix

å¯¹ $Y$ çš„æ¯ä¸€åˆ—åŒæ—¶ç”¨çº¿æ€§å›å½’æ¨¡å‹åšæ‹Ÿåˆå¾—åˆ°ï¼š

- $\hat{Y}=X(X^TX)^{-1}X^TY$
- å¯¹æ¯ä¸€ä¸ªé¢„æµ‹å˜é‡ $Y_k$ æœ‰ç³»æ•°çŸ©é˜µ$\hat B=(X^TX)^{-1}X^TY$. $X$ æœ‰ p + 1åˆ—ï¼Œpä¸ªè¾“å…¥åŠ æˆªè·1.



å¯¹$x$ è¿›è¡Œåˆ†ç±»ï¼š

1. è®¡ç®—æ‹Ÿåˆå€¼$\hat f(x)^T=(1,x^T)\hat B$

2. ç¡®å®šåˆ†ç±» $\hat G(x)=\arg\max_{k\in\mathcal{G}}\hat f_k(x)$

- $\hat f_k(x)$  å¯ä»¥æ˜¯è´Ÿæ•°æˆ–è€…æ¯” 1 å¤§ (çº¿æ€§å›å½’åˆšæ€§æœ¬è´¨ (ridge nature) )





#### LDA: Linear Discriminant Analysis ğŸŒŸğŸŒŸ

TODO
