##### Batch Normalization
- to make error surface landscape more smooth
- issue: different features, some smooth some steep (because value ranges are very different)
- solution: featrue normalization
- method 1:
  - for each feature, x <- (x - m) / sd
  - z's also need normalization(coz W's could have diff ranges), z <- (z - m) / sd
  - problem: as normalization include **other data points'** info, the NN became very large(complicated).
  - so: we use only a batch of data (not all data) -- batch normalization
    - the batch needs to be large enough to be able to get m an sd.
    - if it's large enough, could use batch to represent echop (Approximate)
- method 2:
  - after x <- (x - m) / sd, do x <- r*x + b
  - to help if don't want m == 0 or b == 0. (initialized with r=1 and b=0, and after got to a relative good surface, add r and b slowly into it)
- issue: 
  - in testing, don't know m and sd as the whole batch might not there yet. We use moving average m and sd. ( e.g. m = p * m + (1-p) * m(t) )
- why does Batch Normalization help?
  - Internal Covariate Shift? <- 打脸 How does batch normalization help optimization? (paper: https://arxiv.org/abs/1805.11604)
    - seems batch normalization is serendipitous(偶然的发现)
- Other normalizations (Layer/Instance/Group/Weight/Spectrum Normalization) (papers in PPT)
