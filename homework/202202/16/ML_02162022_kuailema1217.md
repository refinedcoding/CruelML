#### NeuralCF
- Structure
  - NeuralCF 用一个多层的神经网络(MLP)，替代了矩阵分解算法中简单的点积操作，让用户和物品隐向量之间进行充分的交叉。这种通过改进物品隐向量和用户隐向量互操作层的方法，大大增加了模型的拟合能力。
- Innovation
  - Split to two sides: user & item
- Two Towers
  - split the model to user model and item model (any model: embedding; NN), then connect two parts to get the score (any methos: inner product; MLP)
  - Diff
    - NerualCF: just using id features for each side
    - General two-tower model: any features for each side (not only id)
  - Advantage of two-tower model: 易上线、易服务。最终的互操作层是简单的内积操作或浅层神经网络。因此，我们可以把物品塔的输出当作物品 Embedding，用户塔的输出当作用户 Embedding 存入特征数据库，在线上只要实现简单的互操作过程就可以了。
- Questions: 
  - how about context features?
    - 如果希望引入context特征，最好就不用双塔模型，因为双塔模型易线上serving的优势就不存在了. (as context features are changing fast，couldn't be trained offline)
    - 用户的兴趣会随context变化， 但是item的特征不应该随context变化，所以context不应该单独成为一个塔. 可以和user的embed交互作用，形成新的包含context info的user embeding，然后再和item embed 交互作用。（好想法，有启发）
  - News use case:
    - 新闻的场景确实是很有意思的场景，因为时效性很强。这时候新闻id类的特征就不太管用了，因为如果不重新训练，id类特征对应的embedding没办法引入。所以对于这类时效性很强的场景，还是推荐基于一些与id无关的feature来构建模型，比如新闻的类型、人物、地点、关键词等等。
- TODO: 
  - paper: DSSM (与其的比较)
  - paper: Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations
